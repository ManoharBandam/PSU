{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManoharBandam/PSU/blob/master/NROTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDOMWejNf5SQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ADc3iHpOf5PY",
        "outputId": "dd76fa74-10ec-4732-b530-c2ab7e1a2d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1\n",
            "add 200 labeled 1\n",
            "add 200 labeled 2\n",
            "add 200 labeled 3\n",
            "add 200 labeled 4\n",
            "1 1\n",
            "add 200 labeled 0\n",
            "add 200 labeled 2\n",
            "add 200 labeled 3\n",
            "add 200 labeled 4\n",
            "2 0\n",
            "3 1\n",
            "add 200 labeled 0\n",
            "add 200 labeled 1\n",
            "add 200 labeled 2\n",
            "add 200 labeled 4\n",
            "4 1\n",
            "add 200 labeled 0\n",
            "add 200 labeled 1\n",
            "add 200 labeled 2\n",
            "add 200 labeled 3\n",
            "Learning rate:  0.001\n",
            "epoch: 0, avg_train_loss: 0.9885529219093969, training acc:0.7181818181818181\n",
            "test acc: 0.9830706363105662\n",
            "Learning rate:  0.001\n",
            "epoch: 1, avg_train_loss: 0.9362308077027087, training acc:0.7369696969696969\n",
            "test acc: 0.9910488421871959\n",
            "Learning rate:  0.001\n",
            "epoch: 2, avg_train_loss: 0.907103541399607, training acc:0.7434090909090909\n",
            "test acc: 0.9945514691574237\n",
            "Learning rate:  0.001\n",
            "epoch: 3, avg_train_loss: 0.8938598272731172, training acc:0.7478030303030303\n",
            "test acc: 0.9931893364467795\n",
            "Learning rate:  0.001\n",
            "epoch: 4, avg_train_loss: 0.8805072964248011, training acc:0.7492424242424243\n",
            "test acc: 0.9926055652850749\n",
            "Learning rate:  0.001\n",
            "epoch: 5, avg_train_loss: 0.8702908223246836, training acc:0.7515151515151515\n",
            "test acc: 0.9933839268340144\n",
            "Learning rate:  0.001\n",
            "epoch: 6, avg_train_loss: 0.8627984877360069, training acc:0.7529545454545454\n",
            "test acc: 0.9963027826425375\n",
            "Learning rate:  0.001\n",
            "epoch: 7, avg_train_loss: 0.8522873862170711, training acc:0.7543939393939394\n",
            "test acc: 0.9943568787701887\n",
            "Learning rate:  0.001\n",
            "epoch: 8, avg_train_loss: 0.8455320869461965, training acc:0.7545454545454545\n",
            "test acc: 0.9918272037361354\n",
            "Learning rate:  0.001\n",
            "epoch: 9, avg_train_loss: 0.8357758214629591, training acc:0.754469696969697\n",
            "test acc: 0.9949406499318934\n",
            "Learning rate:  0.001\n",
            "epoch: 10, avg_train_loss: 0.8204730090304091, training acc:0.7566666666666667\n",
            "test acc: 0.9937731076084841\n",
            "Learning rate:  0.0001\n",
            "epoch: 11, avg_train_loss: 0.7628120978432764, training acc:0.7631060606060606\n",
            "test acc: 0.9885191671531426\n",
            "Learning rate:  0.0001\n",
            "epoch: 12, avg_train_loss: 0.7361390487478086, training acc:0.7682575757575758\n",
            "test acc: 0.9807355516637478\n",
            "Learning rate:  0.0001\n",
            "epoch: 13, avg_train_loss: 0.7129480579719127, training acc:0.7722727272727272\n",
            "test acc: 0.9692547188168904\n",
            "Learning rate:  0.0001\n",
            "epoch: 14, avg_train_loss: 0.6928790648970707, training acc:0.7788636363636363\n",
            "test acc: 0.9569955244210936\n",
            "Learning rate:  0.0001\n",
            "epoch: 15, avg_train_loss: 0.6680327650276858, training acc:0.7863636363636364\n",
            "test acc: 0.9532983070636311\n",
            "Learning rate:  0.0001\n",
            "epoch: 16, avg_train_loss: 0.646217626499206, training acc:0.7931818181818182\n",
            "test acc: 0.9215800739443472\n",
            "Learning rate:  0.0001\n",
            "epoch: 17, avg_train_loss: 0.6176103603175996, training acc:0.8000757575757576\n",
            "test acc: 0.9250827009145748\n",
            "Learning rate:  0.0001\n",
            "epoch: 18, avg_train_loss: 0.5872563236634322, training acc:0.8122727272727273\n",
            "test acc: 0.9254718816890446\n",
            "Learning rate:  0.0001\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7f32a8469273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0mDataPoisoning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-7f32a8469273>\u001b[0m in \u001b[0;36mDataPoisoning\u001b[0;34m(N0, N1, N2, N3, N4)\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-7f32a8469273>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, net, Train_loader)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# input x and predict based on x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# must be (1. nn output, 2. target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-1cba40a2c423>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch._C import dtype\n",
        "#!/usr/bin/python3\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse, stats\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.utils.data as Data\n",
        "import copy as cp\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import collections\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cats = [0, 1, 2, 3, 4]\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "\tlr = 1e-3\n",
        "\tif epoch > 20:\n",
        "\t\tlr *= 1e-2\n",
        "\telif epoch > 10:\n",
        "\t\tlr *= 1e-1\n",
        "\tprint('Learning rate: ', lr)\n",
        "\n",
        "\treturn lr\n",
        "\n",
        "def test(net, Test_loader):\n",
        "\n",
        "\tnet.eval()\n",
        "\t# test acc\n",
        "\ttotal = 0\n",
        "\tcorrect = 0\n",
        "\twith torch.no_grad():\n",
        "\t\tfor step, (batch_x, batch_y) in enumerate(Test_loader):  # for each training step\n",
        "\n",
        "\t\t\tbatch_x = batch_x.to(device)\n",
        "\t\t\tbatch_y = batch_y.to(device, dtype=torch.long)\n",
        "\n",
        "\t\t\tprediction = net(batch_x)  # input x and predict based on x\n",
        "\t\t\t_, predicted = prediction.max(1)\n",
        "\t\t\ttotal += batch_y.size(0)\n",
        "\t\t\tcorrect += predicted.eq(batch_y).sum().item()\n",
        "\n",
        "\tprint('test acc: {}'.format(correct / total))\n",
        "\n",
        "def train(epoch, net, Train_loader):\n",
        "\n",
        "\t# Optimizer:\n",
        "\toptimizer = torch.optim.Adam(net.parameters(), lr=lr_scheduler(epoch)) # MNIST\n",
        "\n",
        "\t# Loss function\n",
        "\tloss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\t# training\n",
        "\tloss_train = 0\n",
        "\ttotal = 0\n",
        "\tcorrect = 0\n",
        "\n",
        "\tnet.train()\n",
        "\tfor step, (batch_x, batch_y) in enumerate(Train_loader):  # for each training step\n",
        "\n",
        "\t\tbatch_x = batch_x.to(device)\n",
        "\t\tbatch_y = batch_y.to(device, dtype=torch.long)\n",
        "\n",
        "\t\tprediction = net(batch_x)  # input x and predict based on x\n",
        "\n",
        "\t\tloss = loss_func(prediction, batch_y)  # must be (1. nn output, 2. target)\n",
        "\t\tloss_train += loss.item()\n",
        "\n",
        "\t\toptimizer.zero_grad()  # clear gradients for next train\n",
        "\t\tloss.backward()  # backpropagation, compute gradients\n",
        "\t\toptimizer.step()  # apply gradients\n",
        "\n",
        "\t\t_, predicted = prediction.max(1)\n",
        "\t\ttotal += batch_y.size(0)\n",
        "\t\tcorrect += predicted.eq(batch_y).sum().item()\n",
        "\n",
        "\tloss_train = loss_train / (step + 1)\n",
        "\ttrain_acc = correct / total\n",
        "\tprint('epoch: {}, avg_train_loss: {}, training acc:{}'.format(epoch, loss_train, train_acc))\n",
        "\n",
        "\treturn net\n",
        "\n",
        "def classifiers(Train, labelsTrain, Test, labelsTest, classifier):\n",
        "  N, D = Train.shape\n",
        "  if classifier == 'SVM':\n",
        "    clf = linear_model.SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, alpha=0.01, random_state=0) # MNIST\n",
        "    clf.fit(Train, labelsTrain)\n",
        "    pred = clf.predict(Test)\n",
        "    acc = metrics.accuracy_score(labelsTest, pred)\n",
        "    print(\"accuracy of SVM :\", acc)\n",
        "    confusion = metrics.confusion_matrix(labelsTest, pred)\n",
        "    print(confusion)\n",
        "  elif classifier == 'LR':\n",
        "    clf = linear_model.SGDClassifier(loss='log', max_iter=1000, tol=1e-3, alpha=0.01, random_state=0) # MNIST\n",
        "    clf.fit(Train, labelsTrain)\n",
        "    pred = clf.predict(Test)\n",
        "    acc = metrics.accuracy_score(labelsTest, pred)\n",
        "    print(acc)\n",
        "    confusion = metrics.confusion_matrix(labelsTest, pred)\n",
        "    print(confusion)\n",
        "  return acc\n",
        "\n",
        "def KNN_detection(Train, labelsTrain, k=10):\n",
        "  # inputs: training set features and labels, k (# nearest neighbors) \n",
        "  # output: indicators of conjectured malicious samples, 0-normal, 1-malicious, it has the same size as labelsTrain\n",
        "  print(\"Label counts in train data:\", collections.Counter(labelsTrain))\n",
        "\n",
        "  # Fit knn model\n",
        "  knn = NearestNeighbors(n_neighbors = k)\n",
        "  knn.fit(Train)\n",
        "\n",
        "  # distances and indexes of k-neaighbors from model outputs\n",
        "  distances, indexes = knn.kneighbors(Train)\n",
        "  # plot mean of k-distances of each observation\n",
        "  # plt.plot(distances.mean(axis =1)) \n",
        "\n",
        "  # loop over all observations\n",
        "  j = 0\n",
        "  A = np.zeros(labelsTrain.shape)\n",
        "  for row in indexes:\n",
        "    temp = np.zeros(k)\n",
        "    i = 0\n",
        "    #print(\"intermediate mode details:\", row,temp)\n",
        "    for column in row:\n",
        "      temp[i] = labelsTrain[int(column)]\n",
        "      i += 1\n",
        "    #print(\"intermediate mode details:\", row,temp)\n",
        "    mode, freq = stats.mode(temp, axis=None)\n",
        "    #print(\"intermediate mode details:\", mode,freq)    \n",
        "    A[j] =  mode\n",
        "    j += 1\n",
        "  print(\"Label counts in knn predicted data:\", collections.Counter(A))\n",
        "  # print(\"predicted labels:\",A)\n",
        "  # print(A.dtype)\n",
        "  # print(np.unique(A))\n",
        "  # print(labelsTrain[np.logical_not(A)])\n",
        "  # print(np.unique(labelsTrain[np.logical_not(A)]))\n",
        "\n",
        "  # check if predicted label is same as actual label\n",
        "  dp_detected = np.zeros(A.shape)\n",
        "  # malicious samples, 0-normal, 1-malicious\n",
        "  num_of_malicious = 0\n",
        "  non_malicious_labels = []\n",
        "  for i in range(len(labelsTrain)):\n",
        "    if A[i] != labelsTrain[i]:\n",
        "      dp_detected[i] = 1\n",
        "      num_of_malicious += 1\n",
        "    else:\n",
        "      dp_detected[i] = 0\n",
        "      non_malicious_labels.append(labelsTrain[i])\n",
        "  # print(\"non_malicious_labels\",list(set(non_malicious_labels)))\n",
        "  # print(\"malicious samples:\",dp_detected)\n",
        "  # print(\"no of malicious samples:\",num_of_malicious)\n",
        "  # print(\"original samples:\",labelsTrain)\n",
        "  # print(dp_detected.dtype)\n",
        "  # print(np.unique(dp_detected))\n",
        "  # print(np.logical_not(dp_detected))\n",
        "  # print(np.unique(np.logical_not(dp_detected)))\n",
        "  # print(labelsTrain[np.logical_not(dp_detected)])\n",
        "  # print(np.unique(labelsTrain[np.logical_not(dp_detected)]))\n",
        "  return np.asarray(dp_detected)\n",
        "\n",
        "def DataPoisoning(N0, N1, N2, N3, N4):\n",
        "  # Ni: # malicious samples from class i\n",
        "  # cats = [0,1,2,3,4]: 5 classes of MNIST\n",
        "  \n",
        "  Attack = [N0, N1, N2, N3, N4]\n",
        "\n",
        "  # 1.load datasets\n",
        "  transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "  transform_test = transforms.Compose([\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t])\n",
        "  trainset = torchvision.datasets.MNIST(root='./dataset', train=True, download=True, transform=transform_train)\n",
        "  testset = torchvision.datasets.MNIST(root='./dataset', train=False, download=True, transform=transform_test)\n",
        "  attackset = cp.copy(trainset)\n",
        "\n",
        "\t# 2. the experiments only involve 5 classes of MNIST [0, 1, 2, 3, 4]\n",
        "\t# split the training set, 2000 samples per class for training, 1000 samples per class for testing, 800 samples per class for poisoning\n",
        "  NC = len(cats)\n",
        "  nTrain = 2000\n",
        "  nTest = 1000\n",
        "  NAttack = 800\n",
        "\n",
        "\t# labels are stored in a list in datasets, convert it to numpy array\n",
        "  trainset.targets = np.array(trainset.targets)\n",
        "  attackset.targets = np.array(attackset.targets)\n",
        "  testset.targets = np.array(testset.targets)\n",
        "\t# store indices of training samples and malicious samples\n",
        "  ind_training = np.array([], dtype=int)\n",
        "  ind_attack = np.array([], dtype=int)\n",
        "  for c in cats:\n",
        "\t\t# randomly select NTrain+NAttack training samples from class c in [0,1,2,3,4]\n",
        "    ind_c = np.where(trainset.targets == c)[0] \n",
        "    ind_c = np.random.choice(ind_c, nTrain+NAttack, False)\n",
        "\t\t# use a mask to split training samples and malicious samples\n",
        "    mask = np.ones(ind_c.shape, dtype=bool)\n",
        "    mask[:NAttack] = False\n",
        "\t\t# NTrain samples are used for training, NAttack samples are used for poisoning\n",
        "    ind_training = np.concatenate((ind_training, ind_c[mask]))\n",
        "    ind_attack = np.concatenate((ind_attack, ind_c[np.logical_not(mask)]))\n",
        "\t# extract samples by indices\n",
        "  trainset.targets = trainset.targets[ind_training]\n",
        "  trainset.data = trainset.data[ind_training]\n",
        "  attackset.targets = attackset.targets[ind_attack]\n",
        "  attackset.data = attackset.data[ind_attack]\n",
        "\n",
        "\t# store indices of test samples\n",
        "  ind_test = np.array([], dtype=int)\n",
        "\t# only keep test samples from the 5 classes\n",
        "  for c in cats:\n",
        "    ind_c = np.where(testset.targets == c)[0]\n",
        "    ind_test = np.concatenate((ind_test, ind_c))\n",
        "  testset.targets = testset.targets[ind_test]\n",
        "  testset.data = testset.data[ind_test]\n",
        "\n",
        "\t# groundtruth indicators of malicious samples, 0-normal, 1-malicious\n",
        "  Attacks = np.zeros(trainset.targets.shape)\n",
        "\n",
        "\t# 3. poison the training set\n",
        "\t# Attack=[N0,N1,N2,N3,N4]\n",
        "\t# if Ni==1, then evenly distribute samples from class i of the attack set to the training sets of classes c!=i\n",
        "  for j, attack in enumerate(Attack):\n",
        "    print(cats[j], attack)\n",
        "    if attack != 0:\n",
        "      ind = np.where(attackset.targets == cats[j])[0]\n",
        "      trainset.data = torch.cat([trainset.data, attackset.data[ind]], dim=0)\n",
        "      Attacks = np.concatenate((Attacks, np.ones(attackset.targets[ind].shape)))\n",
        "      label = np.array([])\n",
        "      for i in cats:\n",
        "        if i == cats[j]:\n",
        "          continue\n",
        "        label = np.concatenate((label, np.ones(int(NAttack/(NC-1)))*i))\n",
        "        print('add {} labeled {}'.format(int(NAttack/(NC-1)), i))\n",
        "      trainset.targets = np.concatenate((trainset.targets, label))\n",
        "\n",
        "  # 4. form dataloader for CNN\n",
        "  BATCH_SIZE = 32 \n",
        "  EPOCH = 50\n",
        "  Train_loader = Data.DataLoader(\n",
        "    dataset=trainset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, num_workers=1, )\n",
        "\n",
        "  Test_loader = Data.DataLoader(\n",
        "    dataset=testset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, num_workers=1, )\n",
        "\n",
        "  # 5. train ResNet on the poisoned training set\n",
        "  # function train(epoch, net, Train_loader)\n",
        "  # function test(epoch, net, Test_loader)\n",
        "  net = ResNet18(num_classes=NC)\n",
        "  net.to(device)\n",
        "  for epoch in range(EPOCH):\n",
        "    net = train(epoch, net, Train_loader)\n",
        "    test(net, Test_loader)\n",
        "  # save model\n",
        "  if not os.path.isdir('./models/'):\n",
        "    os.makedirs('./models/')\n",
        "  model_path = './models/poisoned_{}_{}_{}_{}_{}.pth'.format(N0, N1, N2, N3, N4)\n",
        "  torch.save(net.state_dict(), model_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  DataPoisoning(N0=1, N1=1, N2=0, N3=1, N4=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIXCTDA0f5AT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrxPAE2SgTe7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HWwH8pmrgTZK",
        "outputId": "29bec933-e236-4a1d-be76-037ee30e070b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "1 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "2 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "3 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "4 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "5 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "6 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "7 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 8\n",
            "add 100 labeled 9\n",
            "8 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 9\n",
            "9 1\n",
            "add 100 labeled 0\n",
            "add 100 labeled 1\n",
            "add 100 labeled 2\n",
            "add 100 labeled 3\n",
            "add 100 labeled 4\n",
            "add 100 labeled 5\n",
            "add 100 labeled 6\n",
            "add 100 labeled 7\n",
            "add 100 labeled 8\n",
            "trainset: 49000\n",
            "testset: 10000\n",
            "Attacks: 49000\n",
            "accuracy with poisoned data : 0.6494\n",
            "[[861   1  17   1   2   0  51   4  43   0]\n",
            " [  0 708   2   0  12  16  63  14 319   1]\n",
            " [ 12   2 829   5  20   2  34   6 118   4]\n",
            " [ 42  27  98 295   3 118  77   4 344   2]\n",
            " [  1   3   5   1 861  12  30   1  65   3]\n",
            " [ 20   8   3  11  15 535 119   8 170   3]\n",
            " [  6   5  11   0  25  21 866   1  23   0]\n",
            " [ 15  17  16   1  47  22  77 534 285  14]\n",
            " [  8   4   4   1  14  15  20   3 903   2]\n",
            " [ 11  11   2   0 266  58 114   7 438 102]]\n",
            "Label counts in train data:\n",
            "Counter({0.0: 4900, 1.0: 4900, 2.0: 4900, 3.0: 4900, 4.0: 4900, 5.0: 4900, 6.0: 4900, 7.0: 4900, 8.0: 4900, 9.0: 4900})\n",
            "Label counts in knn predicted data:\n",
            "Counter({1.0: 5156, 0.0: 4973, 7.0: 4954, 6.0: 4937, 9.0: 4920, 3.0: 4918, 5.0: 4877, 4.0: 4862, 2.0: 4778, 8.0: 4625})\n",
            "tpr: 0.9938888888888889, fpr: 0.02685\n",
            "accuracy with defense: 0.9023\n",
            "[[ 962    0    3    4    1    4    3    2    0    1]\n",
            " [   0 1110    8    3    0    2    4    0    7    1]\n",
            " [  10   10  889   40    9    7   22   13   29    3]\n",
            " [   9    1   18  901    1   41    5   13   14    7]\n",
            " [   3    4    8   11  889    1   11    2   15   38]\n",
            " [  18    2    3   42    6  766   14    4   29    8]\n",
            " [  10    2    7    2    3   31  888    1   14    0]\n",
            " [   1    7   28   12    7    3    1  926    5   38]\n",
            " [  12   11   12   50    4   55    7   11  803    9]\n",
            " [   8    6    5   19   21   10    0   22   29  889]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from torch._C import dtype\n",
        "#!/usr/bin/python3\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse, stats\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.utils.data as Data\n",
        "import copy as cp\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import collections\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cats = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "counter = 0\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "\tlr = 1e-3\n",
        "\tif epoch > 20:\n",
        "\t\tlr *= 1e-2\n",
        "\telif epoch > 10:\n",
        "\t\tlr *= 1e-1\n",
        "\tprint('Learning rate: ', lr)\n",
        "\n",
        "\treturn lr\n",
        "\n",
        "def test(net, Test_loader):\n",
        "\n",
        "\tnet.eval()\n",
        "\t# test acc\n",
        "\ttotal = 0\n",
        "\tcorrect = 0\n",
        "\twith torch.no_grad():\n",
        "\t\tfor step, (batch_x, batch_y) in enumerate(Test_loader):  # for each training step\n",
        "\n",
        "\t\t\tbatch_x = batch_x.to(device)\n",
        "\t\t\tbatch_y = batch_y.to(device, dtype=torch.long)\n",
        "\n",
        "\t\t\tprediction = net(batch_x)  # input x and predict based on x\n",
        "\t\t\t_, predicted = prediction.max(1)\n",
        "\t\t\ttotal += batch_y.size(0)\n",
        "\t\t\tcorrect += predicted.eq(batch_y).sum().item()\n",
        "\n",
        "\tprint('test acc: {}'.format(correct / total))\n",
        "\n",
        "def train(epoch, net, Train_loader):\n",
        "\n",
        "\t# Optimizer:\n",
        "\toptimizer = torch.optim.Adam(net.parameters(), lr=lr_scheduler(epoch)) # MNIST\n",
        "\n",
        "\t# Loss function\n",
        "\tloss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\t# training\n",
        "\tloss_train = 0\n",
        "\ttotal = 0\n",
        "\tcorrect = 0\n",
        "\n",
        "\tnet.train()\n",
        "\tfor step, (batch_x, batch_y) in enumerate(Train_loader):  # for each training step\n",
        "\n",
        "\t\tbatch_x = batch_x.to(device)\n",
        "\t\tbatch_y = batch_y.to(device, dtype=torch.long)\n",
        "\n",
        "\t\tprediction = net(batch_x)  # input x and predict based on x\n",
        "\n",
        "\t\tloss = loss_func(prediction, batch_y)  # must be (1. nn output, 2. target)\n",
        "\t\tloss_train += loss.item()\n",
        "\n",
        "\t\toptimizer.zero_grad()  # clear gradients for next train\n",
        "\t\tloss.backward()  # backpropagation, compute gradients\n",
        "\t\toptimizer.step()  # apply gradients\n",
        "\n",
        "\t\t_, predicted = prediction.max(1)\n",
        "\t\ttotal += batch_y.size(0)\n",
        "\t\tcorrect += predicted.eq(batch_y).sum().item()\n",
        "\n",
        "\tloss_train = loss_train / (step + 1)\n",
        "\ttrain_acc = correct / total\n",
        "\tprint('epoch: {}, avg_train_loss: {}, training acc:{}'.format(epoch, loss_train, train_acc))\n",
        "\n",
        "\treturn net\n",
        "\n",
        "def classifiers(Train, labelsTrain, Test, labelsTest, classifier):\n",
        "  N, D = Train.shape\n",
        "  if classifier == 'SVM':\n",
        "    clf = linear_model.SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, alpha=0.01, random_state=0) # MNIST\n",
        "    clf.fit(Train, labelsTrain)\n",
        "    pred = clf.predict(Test)\n",
        "    acc = metrics.accuracy_score(labelsTest, pred)\n",
        "    confusion = metrics.confusion_matrix(labelsTest, pred)\n",
        "    # print(\"confusion matrix :\")\n",
        "    # print(confusion)\n",
        "  elif classifier == 'LR':\n",
        "    clf = linear_model.SGDClassifier(loss='log', max_iter=1000, tol=1e-3, alpha=0.01, random_state=0) # MNIST\n",
        "    clf.fit(Train, labelsTrain)\n",
        "    pred = clf.predict(Test)\n",
        "    acc = metrics.accuracy_score(labelsTest, pred)\n",
        "    # print(acc)\n",
        "    confusion = metrics.confusion_matrix(labelsTest, pred)\n",
        "    # print(confusion)\n",
        "  return acc,confusion\n",
        "\n",
        "def KNN_detection(Train, labelsTrain, k=10):\n",
        "  # inputs: training set features and labels, k (# nearest neighbors) \n",
        "  # output: indicators of conjectured malicious samples, 0-normal, 1-malicious, it has the same size as labelsTrain\n",
        "  print(\"Label counts in train data:\")\n",
        "  print(collections.Counter(labelsTrain))\n",
        "\n",
        "  # Fit knn model\n",
        "  knn = NearestNeighbors(n_neighbors = k)\n",
        "  knn.fit(Train)\n",
        "\n",
        "  # distances and indexes of k-neaighbors from model outputs\n",
        "  distances, indexes = knn.kneighbors(Train)\n",
        "  # plot mean of k-distances of each observation\n",
        "  # plt.plot(distances.mean(axis =1)) \n",
        "\n",
        "  # loop over all observations\n",
        "  j = 0\n",
        "  A = np.zeros(labelsTrain.shape)\n",
        "  for row in indexes:\n",
        "    temp = np.zeros(k)\n",
        "    i = 0\n",
        "    #print(\"intermediate mode details:\", row,temp)\n",
        "    for column in row:\n",
        "      temp[i] = labelsTrain[int(column)]\n",
        "      i += 1\n",
        "    #print(\"intermediate mode details:\", row,temp)\n",
        "    mode, freq = stats.mode(temp, axis=None)\n",
        "    #print(\"intermediate mode details:\", mode,freq)    \n",
        "    A[j] =  mode\n",
        "    j += 1\n",
        "  print(\"Label counts in knn predicted data:\")\n",
        "  print(collections.Counter(A))\n",
        "  # print(\"predicted labels:\",A)\n",
        "  # print(A.dtype)\n",
        "  # print(np.unique(A))\n",
        "  # print(labelsTrain[np.logical_not(A)])\n",
        "  # print(np.unique(labelsTrain[np.logical_not(A)]))\n",
        "\n",
        "  # check if predicted label is same as actual label\n",
        "  dp_detected = np.zeros(A.shape)\n",
        "  # malicious samples, 0-normal, 1-malicious\n",
        "  num_of_malicious = 0\n",
        "  non_malicious_labels = []\n",
        "  for i in range(len(labelsTrain)):\n",
        "    if A[i] != labelsTrain[i]:\n",
        "      dp_detected[i] = 1\n",
        "      num_of_malicious += 1\n",
        "    else:\n",
        "      dp_detected[i] = 0\n",
        "      non_malicious_labels.append(labelsTrain[i])\n",
        "  # print(\"non_malicious_labels\",list(set(non_malicious_labels)))\n",
        "  # print(\"malicious samples:\",dp_detected)\n",
        "  # print(\"no of malicious samples:\",num_of_malicious)\n",
        "  # print(\"original samples:\",labelsTrain)\n",
        "  # print(dp_detected.dtype)\n",
        "  # print(np.unique(dp_detected))\n",
        "  # print(np.logical_not(dp_detected))\n",
        "  # print(np.unique(np.logical_not(dp_detected)))\n",
        "  # print(labelsTrain[np.logical_not(dp_detected)])\n",
        "  # print(np.unique(labelsTrain[np.logical_not(dp_detected)]))\n",
        "  return np.asarray(dp_detected)\n",
        "\n",
        "def DataPoisoning(N0, N1, N2, N3, N4, N5, N6, N7, N8, N9):\n",
        "\t# Ni: # malicious samples from class i\n",
        "\t# cats = [0,1,2,3,4]: 5 classes of MNIST\n",
        "\n",
        "\tAttack = [N0, N1, N2, N3, N4, N5, N6, N7, N8, N9]\n",
        "\n",
        "\t# 1.load datasets\n",
        "\ttransform_train = transforms.Compose([\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t])\n",
        "\ttransform_test = transforms.Compose([\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t])\n",
        "\ttrainset = torchvision.datasets.MNIST(root='./dataset', train=True, download=True, transform=transform_train)\n",
        "\ttestset = torchvision.datasets.MNIST(root='./dataset', train=False, download=True, transform=transform_test)\n",
        "\tattackset = cp.copy(trainset)\n",
        "\n",
        "\t# 2. the experiments only involve 5 classes of MNIST [0, 1, 2, 3, 4]\n",
        "\t# split the training set, 2000 samples per class for training, 1000 samples per class for testing, 800 samples per class for poisoning\n",
        "\tNC = len(cats)\n",
        "\tnTrain = 4000\n",
        "\tnTest = 1000\n",
        "\tNAttack = 900\n",
        "\n",
        "\t# labels are stored in a list in datasets, convert it to numpy array\n",
        "\ttrainset.targets = np.array(trainset.targets)\n",
        "\tattackset.targets = np.array(attackset.targets)\n",
        "\ttestset.targets = np.array(testset.targets)\n",
        "\t# store indices of training samples and malicious samples\n",
        "\tind_training = np.array([], dtype=int)\n",
        "\tind_attack = np.array([], dtype=int)\n",
        "\tfor c in cats:\n",
        "\t\t# randomly select NTrain+NAttack training samples from class c in [0,1,2,3,4]\n",
        "\t\tind_c = np.where(trainset.targets == c)[0] \n",
        "\t\tind_c = np.random.choice(ind_c, nTrain+NAttack, False)\n",
        "\t\t# use a mask to split training samples and malicious samples\n",
        "\t\tmask = np.ones(ind_c.shape, dtype=bool)\n",
        "\t\tmask[:NAttack] = False\n",
        "\t\t# NTrain samples are used for training, NAttack samples are used for poisoning\n",
        "\t\tind_training = np.concatenate((ind_training, ind_c[mask]))\n",
        "\t\tind_attack = np.concatenate((ind_attack, ind_c[np.logical_not(mask)]))\n",
        "\t# extract samples by indices\n",
        "\ttrainset.targets = trainset.targets[ind_training]\n",
        "\ttrainset.data = trainset.data[ind_training]\n",
        "\tattackset.targets = attackset.targets[ind_attack]\n",
        "\tattackset.data = attackset.data[ind_attack]\n",
        "\n",
        "\t# store indices of test samples\n",
        "\tind_test = np.array([], dtype=int)\n",
        "\t# only keep test samples from the 5 classes\n",
        "\tfor c in cats:\n",
        "\t\tind_c = np.where(testset.targets == c)[0]\n",
        "\t\tind_test = np.concatenate((ind_test, ind_c))\n",
        "\ttestset.targets = testset.targets[ind_test]\n",
        "\ttestset.data = testset.data[ind_test]\n",
        "\n",
        "\t# groundtruth indicators of malicious samples, 0-normal, 1-malicious\n",
        "\tAttacks = np.zeros(trainset.targets.shape)\n",
        "\n",
        "\t# 3. poison the training set\n",
        "\t# Attack=[N0,N1,N2,N3,N4]\n",
        "\t# if Ni==1, then evenly distribute samples from class i of the attack set to the training sets of classes c!=i\n",
        "\tfor j, attack in enumerate(Attack):\n",
        "\t\tprint(cats[j], attack)\n",
        "\t\tif attack != 0:\n",
        "\t\t\tind = np.where(attackset.targets == cats[j])[0]\n",
        "\t\t\ttrainset.data = torch.cat([trainset.data, attackset.data[ind]], dim=0)\n",
        "\t\t\tAttacks = np.concatenate((Attacks, np.ones(attackset.targets[ind].shape)))\n",
        "\t\t\tlabel = np.array([])\n",
        "\t\t\tfor i in cats:\n",
        "\t\t\t\tif i == cats[j]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tlabel = np.concatenate((label, np.ones(int(NAttack/(NC-1)))*i))\n",
        "\t\t\t\tprint('add {} labeled {}'.format(int(NAttack/(NC-1)), i))\n",
        "\t\t\ttrainset.targets = np.concatenate((trainset.targets, label))\n",
        "\n",
        "\treturn trainset, testset, Attacks\n",
        "\n",
        "def main(N0, N1, N2, N3, N4, N5, N6, N7, N8, N9, classifier='SVM'):\n",
        "  \n",
        "  # 1. poison training set\n",
        "  # Attacks: groundtruth indicators of malicious samples, 0-normal, 1-malicious\n",
        "  # Note: it cannot be used in anomaly detection. we only use it in performance evaluation\n",
        "  trainset, testset, Attacks = DataPoisoning(N0, N1, N2, N3, N4, N5, N6, N7, N8, N9)\n",
        "  NC = len(cats)\n",
        "  \n",
        "  print(\"trainset:\",len(trainset))\n",
        "  print(\"testset:\",len(testset))\n",
        "  print(\"Attacks:\",len(Attacks))\n",
        "  # flatten feature matrix, N*28*28 => N*784\n",
        "  features_train = trainset.data.numpy().reshape(len(trainset.targets), -1)\n",
        "  features_test = testset.data.numpy().reshape(len(testset.targets), -1)\n",
        "  \n",
        "  # 2. poisoned acc\n",
        "  if classifier == 'SVM' or classifier == 'LR':\n",
        "    acc, cm = classifiers(features_train, trainset.targets, features_test, testset.targets, classifier)\n",
        "    plot_confusion_matrix(cm, cats, \"confusion matrix poisoned\")\n",
        "    fig2 = plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    print(\"accuracy with poisoned data :\", acc)\n",
        "    print(cm)\n",
        "  else:\n",
        "    BATCH_SIZE = 32\n",
        "    Train_loader_poisoned = Data.DataLoader(\n",
        "        dataset=trainset,\n",
        "        batch_size = BATCH_SIZE,\n",
        "        shuffle=True, num_workers=1, )\n",
        "    Test_loader = Data.DataLoader(\n",
        "        dataset=testset,\n",
        "        batch_size = BATCH_SIZE,\n",
        "        shuffle=True, num_workers=1, )\n",
        "    EPOCH = 10\n",
        "    model_path = './models/KNN_sanitized_{}_{}_{}_{}_{}.pth'.format(N0, N1, N2, N3, N4)\n",
        "    print(\"#######################\")\n",
        "    net1 = ResNet18(num_classes=NC)\n",
        "    net1.to(device)\n",
        "    for epoch in range(EPOCH):\n",
        "      net1 = train(epoch, net1, Train_loader_poisoned)\n",
        "      test(net1, Test_loader)\n",
        "  \n",
        "  # 3. KNN-based detector\n",
        "  # TODO\n",
        "  # inputs: training set features and labels, k(# nearest neighbors)\n",
        "  # output: A, indicators of conjectured malicious samples, 0-normal, 1-malicious, it has the same size as trainset.targets\n",
        "  A = KNN_detection(features_train, trainset.targets, k=10)\n",
        "  \n",
        "  # 4. performance of the anomaly detector\n",
        "  # 1)True positive rate(tpr): # truly detected malicious samples/ total # malicious samples\n",
        "  # 2)False positive rate(fpr): # falsely detected malicious samples/ total # nomal samples\n",
        "  # 3)acc of the classifier trained on the sanitized dataset(with detected malicious samples removed)\n",
        "\n",
        "  TrueAttack = A*Attacks\n",
        "  FalseAttack = A*np.logical_not(Attacks)\n",
        "  if N0 + N1 + N2 + N3 + N4 + N5 + N6 + N7 + N8 + N9 != 0:\n",
        "    tpr = TrueAttack.sum()/(Attacks.sum())\n",
        "  else:\n",
        "    tpr = 0\n",
        "  fpr = FalseAttack.sum()/((1-Attacks).sum())\n",
        "  print(\"tpr: {}, fpr: {}\".format(tpr, fpr))\n",
        "  \n",
        "  if classifier == 'SVM' or classifier == 'LR':\n",
        "    acc2, cm2 = classifiers(features_train[np.logical_not(A)], trainset.targets[np.logical_not(A)], features_test, testset.targets, classifier)\n",
        "    # plot_confusion_matrix(cm2, cats, \"confusion matrix for defense\")\n",
        "    print(\"accuracy with defense:\", acc2)\n",
        "    print(cm2)\n",
        "  else:\n",
        "    BATCH_SIZE = 32\n",
        "    trainset.data = trainset.data[np.logical_not(A)]\n",
        "    trainset.targets = trainset.targets[np.logical_not(A)]\n",
        "    Train_loader_defense = Data.DataLoader(\n",
        "        dataset=trainset,\n",
        "        batch_size = BATCH_SIZE,\n",
        "        shuffle=True, num_workers=1, )\n",
        "    EPOCH = 10\n",
        "    model_path = './models/KNN_sanitized_{}_{}_{}_{}_{}.pth'.format(N0, N1, N2, N3, N4)\n",
        "    print(\"#######################\")\n",
        "    net = ResNet18(num_classes=NC)\n",
        "    net.to(device)\n",
        "    for epoch in range(EPOCH):\n",
        "      net = train(epoch, net, Train_loader_defense)\n",
        "      test(net, Test_loader)\n",
        "    # torch.save(net.state_dict(), model_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain(N0=1, N1=1, N2=1, N3=1, N4=1, N5 = 1, N6 = 1, N7 = 1, N8 = 1, N9 = 1, classifier='SVM')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components = 2, random_state=0)\n",
        "trainset, testset, Attacks = DataPoisoning(1, 1, 1, 1, 0)\n",
        "tsne_res = tsne.fit_transform(trainset)\n",
        "\n",
        "sns.scatterplot(x = tsne_res[:,0], y = tsne_res[:,1], hue = label, palette = sns.hls_palette(10), legend = 'full');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "M3tQsc1AYMhA",
        "outputId": "f05583b4-bfc3-4819-bb42-48dfc4687f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1\n",
            "add 200 labeled 1\n",
            "add 200 labeled 2\n",
            "add 200 labeled 3\n",
            "add 200 labeled 4\n",
            "1 1\n",
            "add 200 labeled 0\n",
            "add 200 labeled 2\n",
            "add 200 labeled 3\n",
            "add 200 labeled 4\n",
            "2 1\n",
            "add 200 labeled 0\n",
            "add 200 labeled 1\n",
            "add 200 labeled 3\n",
            "add 200 labeled 4\n",
            "3 1\n",
            "add 200 labeled 0\n",
            "add 200 labeled 1\n",
            "add 200 labeled 2\n",
            "add 200 labeled 4\n",
            "4 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:746: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = np.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4a04cead23a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPoisoning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtsne_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhls_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \"\"\"\n\u001b[0;32m-> 1108\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             )\n\u001b[1;32m    836\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (13200, 2) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTcAPWS__OcF",
        "outputId": "edc5a7d0-def6-48f4-83d1-ded575dc45eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False,  True,  True, False, False, False])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = [1, 0, 0, 1, 1, 1]\n",
        "B = [0, 0, 0, 4, 4, 4]\n",
        "np.logical_not(A)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YQ1sjpKYxEl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(target_names))\n",
        "    plt.xticks(tick_marks, target_names, rotation=45)\n",
        "    plt.yticks(tick_marks, target_names)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    width, height = cm.shape\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            plt.annotate(str(cm[x][y]), xy=(y, x), \n",
        "                        horizontalalignment='center',\n",
        "                        verticalalignment='center')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    # plt.close()\n",
        "    # plt.figure().clear()\n"
      ],
      "metadata": {
        "id": "1qRn6XP3i8Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OWQUnW0rFxiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Fj8p5rkqbW",
        "outputId": "dcef04ed-0c12-43af-d871-7798f62bef2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjYh-BG1K9PF",
        "outputId": "f0cddefb-81ee-4e6c-ec59-e2af1bd8d00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "malicious samples: [1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "float64\n",
            "[0. 1.]\n"
          ]
        }
      ],
      "source": [
        "dp_detected = np.zeros(10)\n",
        "# malicious samples, 0-normal, 1-malicious\n",
        "for i in range(10):\n",
        "  if i%2 == 0:\n",
        "    dp_detected[i] = 1\n",
        "  else:\n",
        "    dp_detected[i] = 0\n",
        "print(\"malicious samples:\",dp_detected)\n",
        "print(dp_detected.dtype)\n",
        "print(np.unique(dp_detected))\n",
        "# print(labelsTrain[np.logical_not(dp_detected)])\n",
        "# print(np.unique(labelsTrain[np.logical_not(dp_detected)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe6pKewBrPjd",
        "outputId": "6237815e-e9ab-475b-b6c1-1702ae14aa4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Juliet',\n",
              " 'yonder',\n",
              " 'window',\n",
              " 'It',\n",
              " 'east',\n",
              " 'through',\n",
              " 'breaks',\n",
              " 'soft',\n",
              " 'light',\n",
              " 'what',\n",
              " 'fair',\n",
              " 'and',\n",
              " 'is',\n",
              " 'sick',\n",
              " 'sun',\n",
              " 'Who',\n",
              " 'the',\n",
              " 'But',\n",
              " 'already',\n",
              " 'kill',\n",
              " 'moon',\n",
              " 'Arise',\n",
              " 'grief',\n",
              " 'pale',\n",
              " 'envious',\n",
              " 'with']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "myList = ['Arise', 'But', 'It', 'Juliet', 'Who', 'already', 'and', 'and', 'and', \n",
        "     'breaks', 'east', 'envious', 'fair', 'grief', 'is', 'is', 'is', 'kill', 'light', \n",
        "     'moon', 'pale', 'sick', 'soft', 'sun', 'sun', 'the', 'the', 'the', \n",
        "     'through', 'what', 'window', 'with', 'yonder']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XgdmLHU44rtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RWO4aOeZ4rqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YYYSaiEw4rnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eYYVYsie4rjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LR k=10\n",
        "0.6349484335473827\n",
        "[[725   0 225  16  14]\n",
        " [ 25 108 559 167 276]\n",
        " [ 26   0 904  48  54]\n",
        " [ 57   6 334 581  32]\n",
        " [  3   0  31   3 945]]\n",
        "Label counts in train data:\n",
        "Counter({4.0: 2800, 0.0: 2600, 1.0: 2600, 2.0: 2600, 3.0: 2600})\n",
        "Label counts in knn predicted data:\n",
        "Counter({1.0: 2880, 0.0: 2861, 3.0: 2735, 2.0: 2724, 4.0: 2000})\n",
        "tpr: 0.985625, fpr: 0.0167\n",
        "0.9449309204125316\n",
        "[[ 967    0    3    4    6]\n",
        " [   1 1024   58   49    3]\n",
        " [  26    3  942   36   25]\n",
        " [  12    0   26  963    9]\n",
        " [   1    3   14    4  960]]\n",
        "\n",
        "#SVM k=15\n",
        "accuracy of SVM : 0.667639618602841\n",
        "confusion matrix :\n",
        "[[125  73 168 466 148]\n",
        " [  0 772  65  10 288]\n",
        " [  6  18 899  52  57]\n",
        " [  4  12  81 719 194]\n",
        " [  1   4  57   4 916]]\n",
        "Label counts in train data:\n",
        "Counter({4.0: 2800, 0.0: 2600, 1.0: 2600, 2.0: 2600, 3.0: 2600})\n",
        "Label counts in knn predicted data:\n",
        "Counter({1.0: 2887, 0.0: 2841, 3.0: 2734, 2.0: 2727, 4.0: 2011})\n",
        "tpr: 0.986875, fpr: 0.0161\n",
        "accuracy of SVM : 0.9575792955827982\n",
        "confusion matrix :\n",
        "[[ 947    0    8   18    7]\n",
        " [   0 1128    4    3    0]\n",
        " [  17   23  927   43   22]\n",
        " [   7    5   29  965    4]\n",
        " [   0   13    8    7  954]]\n",
        "\n",
        "#SVM k=10\n",
        "accuracy of SVM : 0.72193033664137\n",
        "confusion matrix :\n",
        "[[705 115  24   7 129]\n",
        " [  0 730 359  25  21]\n",
        " [ 19 112 796  27  78]\n",
        " [  8 304 103 524  71]\n",
        " [  2  17   6   2 955]]\n",
        "Label counts in train data:\n",
        "Counter({4.0: 2800, 0.0: 2600, 1.0: 2600, 2.0: 2600, 3.0: 2600})\n",
        "Label counts in knn predicted data:\n",
        "Counter({1.0: 2896, 0.0: 2845, 3.0: 2737, 2.0: 2731, 4.0: 1991})\n",
        "tpr: 0.9840625, fpr: 0.0165\n",
        "accuracy of SVM : 0.9560225724849193\n",
        "confusion matrix :\n",
        "[[ 969    0    5    4    2]\n",
        " [   1 1117    4   12    1]\n",
        " [  43   11  914   48   16]\n",
        " [  13    2   20  970    5]\n",
        " [   7    3   20    9  943]]\n",
        "\n",
        "#SVM k=5\n",
        "accuracy of SVM : 0.7501459427904261\n",
        "confusion matrix :\n",
        "[[668  77 206  10  19]\n",
        " [150 924  33   0  28]\n",
        " [ 79  77 826  14  36]\n",
        " [ 86 212 174 499  39]\n",
        " [  5   8  31   0 938]]\n",
        "Label counts in train data:\n",
        "Counter({4.0: 2800, 0.0: 2600, 1.0: 2600, 2.0: 2600, 3.0: 2600})\n",
        "Label counts in knn predicted data:\n",
        "Counter({1.0: 2884, 0.0: 2872, 3.0: 2735, 2.0: 2709, 4.0: 2000})\n",
        "tpr: 0.9834375, fpr: 0.0181\n",
        "accuracy of SVM : 0.9612765129402607\n",
        "confusion matrix :\n",
        "[[ 960    1   14    4    1]\n",
        " [   2 1125    7    1    0]\n",
        " [   7   14  977   18   16]\n",
        " [  15   11   50  929    5]\n",
        " [   5    7   16    5  949]]"
      ],
      "metadata": {
        "id": "eGNyzK6d8q3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oLPr8aIl4rgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NROTC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXPV1AkT2OYdphhZGX8KRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}