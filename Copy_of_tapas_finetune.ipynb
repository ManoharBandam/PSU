{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tapas_finetune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManoharBandam/PSU/blob/master/Copy_of_tapas_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb#scrollTo=1vfjT1JC_7zI"
      ],
      "metadata": {
        "id": "S2J-LMiVPRSy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r transformers\n",
        "! git clone https://github.com/huggingface/transformers.git\n",
        "! cd transformers\n",
        "! pip install ./transformers"
      ],
      "metadata": {
        "id": "O1iKVAMosxAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02765d71-9328-469e-9d26-832756dd7855"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'transformers': No such file or directory\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 93293, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 93293 (delta 91), reused 139 (delta 54), pack-reused 93088\u001b[K\n",
            "Receiving objects: 100% (93293/93293), 85.73 MiB | 29.78 MiB/s, done.\n",
            "Resolving deltas: 100% (68361/68361), done.\n",
            "Processing ./transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 18.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=4099889 sha256=944a58716da35c6ac797026284aef882927e0b315c347fb1bda26e88d0e960f3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a2oe3sv6/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUR-jmxD-eGg",
        "outputId": "6ab9b78d-5ce9-4d09-af03-94988b0c5333"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=3577514 sha256=abac544eb1fb673d15ed81b22ccc97206dfc610a33994996307ba404f0230cb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_json('sample_data/fetaQA-v1_train.json')\n",
        "data = pd.json_normalize(df1['data'])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "I4rd19oX_cQ-",
        "outputId": "dc68c965-34a4-4d81-8d9e-b0bdc8804f3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feta_id                          table_source_json  \\\n",
              "0    12019  totto_source/train_json/example-4318.json   \n",
              "1    10691  totto_source/train_json/example-2990.json   \n",
              "2     8300   totto_source/train_json/example-599.json   \n",
              "3     8107   totto_source/train_json/example-406.json   \n",
              "4    10564  totto_source/train_json/example-2863.json   \n",
              "\n",
              "                                  page_wikipedia_url  \\\n",
              "0  http://en.wikipedia.org/wiki/Core_fonts_for_th...   \n",
              "1  http://en.wikipedia.org/wiki/Shruti_Haasan_fil...   \n",
              "2  http://en.wikipedia.org/wiki/List_of_Assyrian_...   \n",
              "3  http://en.wikipedia.org/wiki/List_of_Stanley_C...   \n",
              "4  http://en.wikipedia.org/wiki/Estadio_El%C3%ADa...   \n",
              "\n",
              "                table_page_title                    table_section_title  \\\n",
              "0         Core fonts for the Web                List of fonts and files   \n",
              "1      Shruti Haasan filmography                            Filmography   \n",
              "2         List of Assyrian kings  Dynasty of Puzur-Ashur (2025–1749 BC)   \n",
              "3  List of Stanley Cup champions                           Active teams   \n",
              "4          Estadio Elías Aguirre           International matches hosted   \n",
              "\n",
              "                                         table_array  \\\n",
              "0  [[File name, Font name, Variants, Last version...   \n",
              "1  [[Title, Year, Role(s), Director, Language(s),...   \n",
              "2  [[#, Image, King, Reign, Succession, Notes, Re...   \n",
              "3  [[Apps, Team, Wins, Losses, Win %, Years of ap...   \n",
              "4  [[Date, Team #1, Res., Team #2, Round, Attenda...   \n",
              "\n",
              "                                highlighted_cell_ids  \\\n",
              "0  [[1, 1], [1, 3], [9, 1], [9, 3], [20, 1], [20,...   \n",
              "1  [[1, 0], [1, 1], [1, 4], [1, 5], [2, 0], [2, 1...   \n",
              "2           [[5, 2], [6, 2], [6, 4], [7, 2], [7, 4]]   \n",
              "3                   [[1, 1], [1, 2], [3, 1], [3, 2]]   \n",
              "4  [[1, 1], [1, 2], [1, 3], [1, 4], [5, 1], [5, 2...   \n",
              "\n",
              "                                            question  \\\n",
              "0  What were the font-versions that were availabl...   \n",
              "1  In what films has Shruti Haasan made a cameo a...   \n",
              "2  On the Assyrian King List, for whom is Sargon ...   \n",
              "3  How many Stanley Cup championships did Toronto...   \n",
              "4  What were the first and final Copa América mat...   \n",
              "\n",
              "                                              answer          source  \n",
              "0  The font-versions that were available from Cor...  mturk-approved  \n",
              "1  Shruti Haasan made a cameo appearance in Tamil...        internal  \n",
              "2  On the Assyrian King List, Sargon appears as t...        internal  \n",
              "3  The Toronto Maple Leafs has won thirteen Stanl...        internal  \n",
              "4  The game that opened the Elías Aguirre's parti...        internal  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4270ca8-3271-4612-b729-fca50d9df3d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feta_id</th>\n",
              "      <th>table_source_json</th>\n",
              "      <th>page_wikipedia_url</th>\n",
              "      <th>table_page_title</th>\n",
              "      <th>table_section_title</th>\n",
              "      <th>table_array</th>\n",
              "      <th>highlighted_cell_ids</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12019</td>\n",
              "      <td>totto_source/train_json/example-4318.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Core_fonts_for_th...</td>\n",
              "      <td>Core fonts for the Web</td>\n",
              "      <td>List of fonts and files</td>\n",
              "      <td>[[File name, Font name, Variants, Last version...</td>\n",
              "      <td>[[1, 1], [1, 3], [9, 1], [9, 3], [20, 1], [20,...</td>\n",
              "      <td>What were the font-versions that were availabl...</td>\n",
              "      <td>The font-versions that were available from Cor...</td>\n",
              "      <td>mturk-approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10691</td>\n",
              "      <td>totto_source/train_json/example-2990.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Shruti_Haasan_fil...</td>\n",
              "      <td>Shruti Haasan filmography</td>\n",
              "      <td>Filmography</td>\n",
              "      <td>[[Title, Year, Role(s), Director, Language(s),...</td>\n",
              "      <td>[[1, 0], [1, 1], [1, 4], [1, 5], [2, 0], [2, 1...</td>\n",
              "      <td>In what films has Shruti Haasan made a cameo a...</td>\n",
              "      <td>Shruti Haasan made a cameo appearance in Tamil...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8300</td>\n",
              "      <td>totto_source/train_json/example-599.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Assyrian_...</td>\n",
              "      <td>List of Assyrian kings</td>\n",
              "      <td>Dynasty of Puzur-Ashur (2025–1749 BC)</td>\n",
              "      <td>[[#, Image, King, Reign, Succession, Notes, Re...</td>\n",
              "      <td>[[5, 2], [6, 2], [6, 4], [7, 2], [7, 4]]</td>\n",
              "      <td>On the Assyrian King List, for whom is Sargon ...</td>\n",
              "      <td>On the Assyrian King List, Sargon appears as t...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8107</td>\n",
              "      <td>totto_source/train_json/example-406.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Stanley_C...</td>\n",
              "      <td>List of Stanley Cup champions</td>\n",
              "      <td>Active teams</td>\n",
              "      <td>[[Apps, Team, Wins, Losses, Win %, Years of ap...</td>\n",
              "      <td>[[1, 1], [1, 2], [3, 1], [3, 2]]</td>\n",
              "      <td>How many Stanley Cup championships did Toronto...</td>\n",
              "      <td>The Toronto Maple Leafs has won thirteen Stanl...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10564</td>\n",
              "      <td>totto_source/train_json/example-2863.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Estadio_El%C3%ADa...</td>\n",
              "      <td>Estadio Elías Aguirre</td>\n",
              "      <td>International matches hosted</td>\n",
              "      <td>[[Date, Team #1, Res., Team #2, Round, Attenda...</td>\n",
              "      <td>[[1, 1], [1, 2], [1, 3], [1, 4], [5, 1], [5, 2...</td>\n",
              "      <td>What were the first and final Copa América mat...</td>\n",
              "      <td>The game that opened the Elías Aguirre's parti...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4270ca8-3271-4612-b729-fca50d9df3d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4270ca8-3271-4612-b729-fca50d9df3d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4270ca8-3271-4612-b729-fca50d9df3d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoYKFzqklZIe",
        "outputId": "651ffb1c-6124-4322-f9d9-64997d0ba7b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feta_id                 0\n",
              "table_source_json       0\n",
              "page_wikipedia_url      0\n",
              "table_page_title        0\n",
              "table_section_title     0\n",
              "table_array             0\n",
              "highlighted_cell_ids    0\n",
              "question                0\n",
              "answer                  0\n",
              "source                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def _parse_highlighted_coordinates(answer_coordinate_str):\n",
        "  \"\"\"Parses the answer_coordinates of a question.\n",
        "  Args:\n",
        "    answer_coordinate_str: A string representation of a Python list of tuple\n",
        "      strings.\n",
        "      For example: \"['(1, 4)','(1, 3)', ...]\"\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    answer_coordinates = []\n",
        "    # make a list of strings\n",
        "    # parse each string as a tuple\n",
        "    for idx in answer_coordinate_str:\n",
        "      answer_coordinates.append(tuple(idx))\n",
        "  except SyntaxError:\n",
        "    raise ValueError('Unable to evaluate %s' % answer_coordinate_str)\n",
        "  answer_coordinates_dtemp = []\n",
        "  answer_coordinates_dtemp.append(answer_coordinates)\n",
        "  return answer_coordinates_dtemp\n",
        "\n",
        "def _parse_answer_text(answer_text):\n",
        "  \"\"\"Populates the answer_texts field of `answer` by parsing `answer_text`.\n",
        "  Args:\n",
        "    answer_text: A string representation of a Python list of strings.\n",
        "      For example: \"[u'test', u'hello', ...]\"\n",
        "    answer: an Answer object.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    answer = []\n",
        "    answer.append(answer_text)\n",
        "\n",
        "  except SyntaxError:\n",
        "    raise ValueError('Unable to evaluate %s' % answer_text)\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "data['highlighted_cell_ids'] = data['highlighted_cell_ids'].apply(lambda coords_str: _parse_highlighted_coordinates(coords_str))\n",
        "data['answer'] = data['answer'].apply(lambda txt: _parse_answer_text(txt))\n",
        "data['question'] = data['question'].apply(lambda txt: _parse_answer_text(txt))\n",
        "\n",
        "for i in len(data):\n",
        "  if i['answer'] == []:\n",
        "    \n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "qq96_uFL-eDP",
        "outputId": "b9182b21-eda5-4994-ff6b-dfffd89287e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feta_id                          table_source_json  \\\n",
              "0    12019  totto_source/train_json/example-4318.json   \n",
              "1    10691  totto_source/train_json/example-2990.json   \n",
              "2     8300   totto_source/train_json/example-599.json   \n",
              "3     8107   totto_source/train_json/example-406.json   \n",
              "4    10564  totto_source/train_json/example-2863.json   \n",
              "\n",
              "                                  page_wikipedia_url  \\\n",
              "0  http://en.wikipedia.org/wiki/Core_fonts_for_th...   \n",
              "1  http://en.wikipedia.org/wiki/Shruti_Haasan_fil...   \n",
              "2  http://en.wikipedia.org/wiki/List_of_Assyrian_...   \n",
              "3  http://en.wikipedia.org/wiki/List_of_Stanley_C...   \n",
              "4  http://en.wikipedia.org/wiki/Estadio_El%C3%ADa...   \n",
              "\n",
              "                table_page_title                    table_section_title  \\\n",
              "0         Core fonts for the Web                List of fonts and files   \n",
              "1      Shruti Haasan filmography                            Filmography   \n",
              "2         List of Assyrian kings  Dynasty of Puzur-Ashur (2025–1749 BC)   \n",
              "3  List of Stanley Cup champions                           Active teams   \n",
              "4          Estadio Elías Aguirre           International matches hosted   \n",
              "\n",
              "                                         table_array  \\\n",
              "0  [[File name, Font name, Variants, Last version...   \n",
              "1  [[Title, Year, Role(s), Director, Language(s),...   \n",
              "2  [[#, Image, King, Reign, Succession, Notes, Re...   \n",
              "3  [[Apps, Team, Wins, Losses, Win %, Years of ap...   \n",
              "4  [[Date, Team #1, Res., Team #2, Round, Attenda...   \n",
              "\n",
              "                                highlighted_cell_ids  \\\n",
              "0  [[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20...   \n",
              "1  [[(1, 0), (1, 1), (1, 4), (1, 5), (2, 0), (2, ...   \n",
              "2         [[(5, 2), (6, 2), (6, 4), (7, 2), (7, 4)]]   \n",
              "3                 [[(1, 1), (1, 2), (3, 1), (3, 2)]]   \n",
              "4  [[(1, 1), (1, 2), (1, 3), (1, 4), (5, 1), (5, ...   \n",
              "\n",
              "                                            question  \\\n",
              "0  [What were the font-versions that were availab...   \n",
              "1  [In what films has Shruti Haasan made a cameo ...   \n",
              "2  [On the Assyrian King List, for whom is Sargon...   \n",
              "3  [How many Stanley Cup championships did Toront...   \n",
              "4  [What were the first and final Copa América ma...   \n",
              "\n",
              "                                              answer          source  \n",
              "0  [The font-versions that were available from Co...  mturk-approved  \n",
              "1  [Shruti Haasan made a cameo appearance in Tami...        internal  \n",
              "2  [On the Assyrian King List, Sargon appears as ...        internal  \n",
              "3  [The Toronto Maple Leafs has won thirteen Stan...        internal  \n",
              "4  [The game that opened the Elías Aguirre's part...        internal  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a7e59c8-366d-43bc-b29f-5463aefd785f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feta_id</th>\n",
              "      <th>table_source_json</th>\n",
              "      <th>page_wikipedia_url</th>\n",
              "      <th>table_page_title</th>\n",
              "      <th>table_section_title</th>\n",
              "      <th>table_array</th>\n",
              "      <th>highlighted_cell_ids</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12019</td>\n",
              "      <td>totto_source/train_json/example-4318.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Core_fonts_for_th...</td>\n",
              "      <td>Core fonts for the Web</td>\n",
              "      <td>List of fonts and files</td>\n",
              "      <td>[[File name, Font name, Variants, Last version...</td>\n",
              "      <td>[[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20...</td>\n",
              "      <td>[What were the font-versions that were availab...</td>\n",
              "      <td>[The font-versions that were available from Co...</td>\n",
              "      <td>mturk-approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10691</td>\n",
              "      <td>totto_source/train_json/example-2990.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Shruti_Haasan_fil...</td>\n",
              "      <td>Shruti Haasan filmography</td>\n",
              "      <td>Filmography</td>\n",
              "      <td>[[Title, Year, Role(s), Director, Language(s),...</td>\n",
              "      <td>[[(1, 0), (1, 1), (1, 4), (1, 5), (2, 0), (2, ...</td>\n",
              "      <td>[In what films has Shruti Haasan made a cameo ...</td>\n",
              "      <td>[Shruti Haasan made a cameo appearance in Tami...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8300</td>\n",
              "      <td>totto_source/train_json/example-599.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Assyrian_...</td>\n",
              "      <td>List of Assyrian kings</td>\n",
              "      <td>Dynasty of Puzur-Ashur (2025–1749 BC)</td>\n",
              "      <td>[[#, Image, King, Reign, Succession, Notes, Re...</td>\n",
              "      <td>[[(5, 2), (6, 2), (6, 4), (7, 2), (7, 4)]]</td>\n",
              "      <td>[On the Assyrian King List, for whom is Sargon...</td>\n",
              "      <td>[On the Assyrian King List, Sargon appears as ...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8107</td>\n",
              "      <td>totto_source/train_json/example-406.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Stanley_C...</td>\n",
              "      <td>List of Stanley Cup champions</td>\n",
              "      <td>Active teams</td>\n",
              "      <td>[[Apps, Team, Wins, Losses, Win %, Years of ap...</td>\n",
              "      <td>[[(1, 1), (1, 2), (3, 1), (3, 2)]]</td>\n",
              "      <td>[How many Stanley Cup championships did Toront...</td>\n",
              "      <td>[The Toronto Maple Leafs has won thirteen Stan...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10564</td>\n",
              "      <td>totto_source/train_json/example-2863.json</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Estadio_El%C3%ADa...</td>\n",
              "      <td>Estadio Elías Aguirre</td>\n",
              "      <td>International matches hosted</td>\n",
              "      <td>[[Date, Team #1, Res., Team #2, Round, Attenda...</td>\n",
              "      <td>[[(1, 1), (1, 2), (1, 3), (1, 4), (5, 1), (5, ...</td>\n",
              "      <td>[What were the first and final Copa América ma...</td>\n",
              "      <td>[The game that opened the Elías Aguirre's part...</td>\n",
              "      <td>internal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a7e59c8-366d-43bc-b29f-5463aefd785f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a7e59c8-366d-43bc-b29f-5463aefd785f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a7e59c8-366d-43bc-b29f-5463aefd785f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUpBNpYglq2k",
        "outputId": "4760691d-541e-470b-982f-ceeaf1132bbe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feta_id                 0\n",
              "table_source_json       0\n",
              "page_wikipedia_url      0\n",
              "table_page_title        0\n",
              "table_section_title     0\n",
              "table_array             0\n",
              "highlighted_cell_ids    0\n",
              "question                0\n",
              "answer                  0\n",
              "source                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.DataFrame(data[\"table_array\"][0])\n",
        "table.columns = table.iloc[0]\n",
        "table = table.iloc[1: , :].reset_index(drop=True).astype(str)\n",
        "item = data.iloc[0]\n",
        "# display(table)\n",
        "print(item)\n",
        "print(item.highlighted_cell_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcWc7fkLD9X2",
        "outputId": "263c94fa-bd66-49a9-d9a4-66a91c5a0d1e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feta_id                                                             12019\n",
            "table_source_json               totto_source/train_json/example-4318.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Core_fonts_for_th...\n",
            "table_page_title                                   Core fonts for the Web\n",
            "table_section_title                               List of fonts and files\n",
            "table_array             [[File name, Font name, Variants, Last version...\n",
            "highlighted_cell_ids    [[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20...\n",
            "question                [What were the font-versions that were availab...\n",
            "answer                  [The font-versions that were available from Co...\n",
            "source                                                     mturk-approved\n",
            "Name: 0, dtype: object\n",
            "[[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20, 3)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "16m_H0G6HoDb",
        "outputId": "d41feb92-c461-4ff9-8dd6-d4a87b63f0cb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           File name                                        Font name  \\\n",
              "0         arial32.exe        Arial for Windows 9x, NT and Windows 2000   \n",
              "1       Arial.sit.hqx                           Arial for Apple Mac OS   \n",
              "2        arialb32.exe  Arial Black for Windows 9x, NT and Windows 2000   \n",
              "3          ariblk.exe             Arial Black for Windows 3.1 and 3.11   \n",
              "4  ArialBlack.sit.hqx                     Arial Black for Apple Mac OS   \n",
              "\n",
              "0                            Variants  Last version Copyright Sample  \n",
              "0  regular, bold, italic, bold italic  version 2.82  Monotype      -  \n",
              "1  regular, bold, italic, bold italic  version 2.90  Monotype      -  \n",
              "2                               black  version 2.35  Monotype      -  \n",
              "3                               black  version 2.20  Monotype      -  \n",
              "4                               black  version 2.35  Monotype      -  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e872db2-349d-4722-b7f3-ba48c277c0a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File name</th>\n",
              "      <th>Font name</th>\n",
              "      <th>Variants</th>\n",
              "      <th>Last version</th>\n",
              "      <th>Copyright</th>\n",
              "      <th>Sample</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arial32.exe</td>\n",
              "      <td>Arial for Windows 9x, NT and Windows 2000</td>\n",
              "      <td>regular, bold, italic, bold italic</td>\n",
              "      <td>version 2.82</td>\n",
              "      <td>Monotype</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Arial.sit.hqx</td>\n",
              "      <td>Arial for Apple Mac OS</td>\n",
              "      <td>regular, bold, italic, bold italic</td>\n",
              "      <td>version 2.90</td>\n",
              "      <td>Monotype</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arialb32.exe</td>\n",
              "      <td>Arial Black for Windows 9x, NT and Windows 2000</td>\n",
              "      <td>black</td>\n",
              "      <td>version 2.35</td>\n",
              "      <td>Monotype</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ariblk.exe</td>\n",
              "      <td>Arial Black for Windows 3.1 and 3.11</td>\n",
              "      <td>black</td>\n",
              "      <td>version 2.20</td>\n",
              "      <td>Monotype</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ArialBlack.sit.hqx</td>\n",
              "      <td>Arial Black for Apple Mac OS</td>\n",
              "      <td>black</td>\n",
              "      <td>version 2.35</td>\n",
              "      <td>Monotype</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e872db2-349d-4722-b7f3-ba48c277c0a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e872db2-349d-4722-b7f3-ba48c277c0a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e872db2-349d-4722-b7f3-ba48c277c0a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import TapasTokenizer\n",
        "\n",
        "# initialize the tokenizer\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")"
      ],
      "metadata": {
        "id": "4xG4gnjACeEV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer(table=table, queries=item.question, answer_coordinates=item.highlighted_cell_ids, answer_text=item.answer,\n",
        "                     truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "encoding.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOVOIZF-CeBj",
        "outputId": "943d279f-7fe9-4523-997d-3f557339dfff"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'labels', 'numeric_values', 'numeric_values_scale', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoding[\"input_ids\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "4Cm7qWZECd-o",
        "outputId": "19dba6d1-6255-41fd-9747-25d6a8c5b3dc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] what were the font - versions that were available from core fonts for the web project published in 2000? [SEP] file name font name variants last version copyright sample arial32 arial for regular, bold version 2. monotype [EMPTY] arial. arial for regular, bold version 2. monotype [EMPTY] arialb32 arial black black version 2. monotype [EMPTY] ariblk arial black black version 2. monotype [EMPTY] arialblack arial black black version 2. monotype [EMPTY] andale32 andale mono regular version 2. monotype [EMPTY] andalemono andale mono regular version 2. monotype [EMPTY] mtcom. monotype. regular version 1. monotype [EMPTY] courie32 courier new for regular, bold version 2. monotype [EMPTY] couriernew courier new for regular, bold version 2. monotype [EMPTY] comic32. comic sans ms regular, bold version 2. microsoft [EMPTY] comic. exe comic sans ms regular, bold version 1. microsoft [EMPTY] comicsans. comic sans ms regular, bold version 2. microsoft [EMPTY] georgi32 georgia for windows regular, bold version 2. microsoft [EMPTY] georgia. exe georgia for windows regular, bold version 1. microsoft [EMPTY] georgia. sit georgia for apple regular, bold version 2. microsoft [EMPTY] impact32. impact for windows regular version 2. monotype [EMPTY] impact. exe impact for windows regular version 2. monotype [EMPTY] impact. sit impact for apple regular version 2. monotype [EMPTY] times32. times new roman regular, bold version 2. monotype [EMPTY] timesnew times new roman regular, bold version 2. monotype [EMPTY] trebuc32 trebuchet regular, bold version 1. microsoft [EMPTY] trebuc trebuchet regular, bold version 1. microsoft [EMPTY] trebuchet trebuchet regular, bold version 1. microsoft [EMPTY] verdan32 verdana regular, bold version 2. microsoft [EMPTY] verdana verdana regular, bold version 1. microsoft [EMPTY] verdana verdana regular, bold version 2. microsoft [EMPTY] webdin32 webdings symbol version 1. microsoft [EMPTY] webdings webdings symbol version 1. microsoft [EMPTY] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert encoding[\"token_type_ids\"][0][:,3].sum() == 0"
      ],
      "metadata": {
        "id": "gQxPOASSCd40"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(item.answer[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAPUQTfTCd18",
        "outputId": "a3606eb1-03fe-4436-e965-b96517183fb1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The font-versions that were available from Core fonts for the Web project were 2.x (e.g. 2.82 for Arial, Times New Roman and Courier New for MS Windows), published in 2000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding"
      ],
      "metadata": {
        "id": "xClcNqFOxrP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding[\"token_type_ids\"][0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNpCMzZXw4QN",
        "outputId": "6ce7d39a-0f37-4230-cc26-e1b11b3a9329"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTSEcpIE6_6i",
        "outputId": "7d3433d5-f364-4425-b97f-a7d998db089c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2054,  2020,  1996, 15489,  1011,  4617,  2008,  2020,  2800,\n",
              "          2013,  4563, 15489,  2015,  2005,  1996,  4773,  2622,  2405,  1999,\n",
              "          2456,  1029,   102,  5371,  2171, 15489,  2171, 10176,  2197,  2544,\n",
              "          9385,  7099,  9342,  2140, 16703,  9342,  2140,  2005,  3180,  1010,\n",
              "          7782,  2544,  1016,  1012, 18847, 13874,     1,  9342,  2140,  1012,\n",
              "          9342,  2140,  2005,  3180,  1010,  7782,  2544,  1016,  1012, 18847,\n",
              "         13874,     1,  9342, 20850, 16703,  9342,  2140,  2304,  2304,  2544,\n",
              "          1016,  1012, 18847, 13874,     1, 10488, 16558,  2243,  9342,  2140,\n",
              "          2304,  2304,  2544,  1016,  1012, 18847, 13874,     1,  9342, 20850,\n",
              "          2721,  3600,  9342,  2140,  2304,  2304,  2544,  1016,  1012, 18847,\n",
              "         13874,     1,  1998,  9453, 16703,  1998,  9453, 18847,  3180,  2544,\n",
              "          1016,  1012, 18847, 13874,     1,  1998,  9453,  8202,  2080,  1998,\n",
              "          9453, 18847,  3180,  2544,  1016,  1012, 18847, 13874,     1, 11047,\n",
              "          9006,  1012, 18847, 13874,  1012,  3180,  2544,  1015,  1012, 18847,\n",
              "         13874,     1,  2522,  9496,  2063, 16703, 18092,  2047,  2005,  3180,\n",
              "          1010,  7782,  2544,  1016,  1012, 18847, 13874,     1, 18092,  2638,\n",
              "          2860, 18092,  2047,  2005,  3180,  1010,  7782,  2544,  1016,  1012,\n",
              "         18847, 13874,     1,  5021, 16703,  1012,  5021, 20344,  5796,  3180,\n",
              "          1010,  7782,  2544,  1016,  1012,  7513,     1,  5021,  1012,  4654,\n",
              "          2063,  5021, 20344,  5796,  3180,  1010,  7782,  2544,  1015,  1012,\n",
              "          7513,     1,  5888,  6962,  1012,  5021, 20344,  5796,  3180,  1010,\n",
              "          7782,  2544,  1016,  1012,  7513,     1, 12062,  2072, 16703,  4108,\n",
              "          2005,  3645,  3180,  1010,  7782,  2544,  1016,  1012,  7513,     1,\n",
              "          4108,  1012,  4654,  2063,  4108,  2005,  3645,  3180,  1010,  7782,\n",
              "          2544,  1015,  1012,  7513,     1,  4108,  1012,  4133,  4108,  2005,\n",
              "          6207,  3180,  1010,  7782,  2544,  1016,  1012,  7513,     1,  4254,\n",
              "         16703,  1012,  4254,  2005,  3645,  3180,  2544,  1016,  1012, 18847,\n",
              "         13874,     1,  4254,  1012,  4654,  2063,  4254,  2005,  3645,  3180,\n",
              "          2544,  1016,  1012, 18847, 13874,     1,  4254,  1012,  4133,  4254,\n",
              "          2005,  6207,  3180,  2544,  1016,  1012, 18847, 13874,     1,  2335,\n",
              "         16703,  1012,  2335,  2047,  3142,  3180,  1010,  7782,  2544,  1016,\n",
              "          1012, 18847, 13874,     1,  2335,  2638,  2860,  2335,  2047,  3142,\n",
              "          3180,  1010,  7782,  2544,  1016,  1012, 18847, 13874,     1, 29461,\n",
              "          8569,  2278, 16703, 29461, 25987,  3388,  3180,  1010,  7782,  2544,\n",
              "          1015,  1012,  7513,     1, 29461,  8569,  2278, 29461, 25987,  3388,\n",
              "          3180,  1010,  7782,  2544,  1015,  1012,  7513,     1, 29461, 25987,\n",
              "          3388, 29461, 25987,  3388,  3180,  1010,  7782,  2544,  1015,  1012,\n",
              "          7513,     1,  2310, 26992, 16703,  2310, 26992,  2050,  3180,  1010,\n",
              "          7782,  2544,  1016,  1012,  7513,     1,  2310, 26992,  2050,  2310,\n",
              "         26992,  2050,  3180,  1010,  7782,  2544,  1015,  1012,  7513,     1,\n",
              "          2310, 26992,  2050,  2310, 26992,  2050,  3180,  1010,  7782,  2544,\n",
              "          1016,  1012,  7513,     1,  4773,  8718, 16703,  4773,  4667,  2015,\n",
              "          6454,  2544,  1015,  1012,  7513,     1,  4773,  4667,  2015,  4773,\n",
              "          4667,  2015,  6454,  2544,  1015,  1012,  7513,     1,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_copy = data.copy()\n",
        "data = data.drop(5)\n",
        "data=data.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pC54GleCC0xi"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TableDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.df.iloc[idx]\n",
        "        table = pd.DataFrame(self.df[\"table_array\"][idx]) # TapasTokenizer expects the table data to be text only\n",
        "          # this means it's the first table-question pair in a sequence\n",
        "        table.columns = table.iloc[0]\n",
        "        table = table.iloc[1: , :].reset_index(drop=True)\n",
        "        # if item.\n",
        "        print(item)\n",
        "        encoding = self.tokenizer(table=table, \n",
        "                                  queries=item.question, \n",
        "                                  answer_coordinates=item.highlighted_cell_ids, \n",
        "                                  answer_text=item.answer,\n",
        "                                  padding=\"max_length\",\n",
        "                                  truncation=True,\n",
        "                                  return_tensors=\"pt\"\n",
        "        )\n",
        "        # remove the batch dimension which the tokenizer adds \n",
        "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        # previous_item = self.df.iloc[idx-1]\n",
        "        # encoding = self.tokenizer(table=table, \n",
        "        #                           queries=[previous_item.question, item.question], \n",
        "        #                           answer_coordinates=[previous_item.highlighted_cell_ids, item.highlighted_cell_ids], \n",
        "        #                           answer_text=[previous_item.answer, item.answer],\n",
        "        #                           padding=\"max_length\",\n",
        "        #                           truncation=True,\n",
        "        #                           return_tensors=\"pt\"\n",
        "        # )\n",
        "        # # use encodings of second table-question pair in the batch\n",
        "        # encoding = {key: val[-1] for key, val in encoding.items()}\n",
        "        return encoding\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "train_dataset = TableDataset(df=data, tokenizer=tokenizer)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=3)"
      ],
      "metadata": {
        "id": "2fwTmw-gCdy4"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][\"token_type_ids\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PapYZcvTCdv1",
        "outputId": "08b6ced3-7a7d-4c57-9407-a2c19a129e5f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feta_id                                                             12019\n",
            "table_source_json               totto_source/train_json/example-4318.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Core_fonts_for_th...\n",
            "table_page_title                                   Core fonts for the Web\n",
            "table_section_title                               List of fonts and files\n",
            "table_array             [[File name, Font name, Variants, Last version...\n",
            "highlighted_cell_ids    [[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20...\n",
            "question                [What were the font-versions that were availab...\n",
            "answer                  [The font-versions that were available from Co...\n",
            "source                                                     mturk-approved\n",
            "Name: 0, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[1][\"input_ids\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RidfATTICdtF",
        "outputId": "3a01fd9c-d1fa-4c56-bd8a-d7a6cd6f2f34"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feta_id                                                             10691\n",
            "table_source_json               totto_source/train_json/example-2990.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Shruti_Haasan_fil...\n",
            "table_page_title                                Shruti Haasan filmography\n",
            "table_section_title                                           Filmography\n",
            "table_array             [[Title, Year, Role(s), Director, Language(s),...\n",
            "highlighted_cell_ids    [[(1, 0), (1, 1), (1, 4), (1, 5), (2, 0), (2, ...\n",
            "question                [In what films has Shruti Haasan made a cameo ...\n",
            "answer                  [Shruti Haasan made a cameo appearance in Tami...\n",
            "source                                                           internal\n",
            "Name: 1, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gab6s0W8sZbx",
        "outputId": "983a6029-5b4f-4a99-c429-43ab85d3192d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f5ec960d850>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmt454E0CdqJ",
        "outputId": "5781b8d6-cb44-4bb1-cedc-14b935348b40"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feta_id                                                             12019\n",
            "table_source_json               totto_source/train_json/example-4318.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Core_fonts_for_th...\n",
            "table_page_title                                   Core fonts for the Web\n",
            "table_section_title                               List of fonts and files\n",
            "table_array             [[File name, Font name, Variants, Last version...\n",
            "highlighted_cell_ids    [[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20...\n",
            "question                [What were the font-versions that were availab...\n",
            "answer                  [The font-versions that were available from Co...\n",
            "source                                                     mturk-approved\n",
            "Name: 0, dtype: object\n",
            "feta_id                                                             10691\n",
            "table_source_json               totto_source/train_json/example-2990.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Shruti_Haasan_fil...\n",
            "table_page_title                                Shruti Haasan filmography\n",
            "table_section_title                                           Filmography\n",
            "table_array             [[Title, Year, Role(s), Director, Language(s),...\n",
            "highlighted_cell_ids    [[(1, 0), (1, 1), (1, 4), (1, 5), (2, 0), (2, ...\n",
            "question                [In what films has Shruti Haasan made a cameo ...\n",
            "answer                  [Shruti Haasan made a cameo appearance in Tami...\n",
            "source                                                           internal\n",
            "Name: 1, dtype: object\n",
            "feta_id                                                              8300\n",
            "table_source_json                totto_source/train_json/example-599.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/List_of_Assyrian_...\n",
            "table_page_title                                   List of Assyrian kings\n",
            "table_section_title                 Dynasty of Puzur-Ashur (2025–1749 BC)\n",
            "table_array             [[#, Image, King, Reign, Succession, Notes, Re...\n",
            "highlighted_cell_ids           [[(5, 2), (6, 2), (6, 4), (7, 2), (7, 4)]]\n",
            "question                [On the Assyrian King List, for whom is Sargon...\n",
            "answer                  [On the Assyrian King List, Sargon appears as ...\n",
            "source                                                           internal\n",
            "Name: 2, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"input_ids\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQbAivQwCdnq",
        "outputId": "8149d880-81ad-49dc-c9fb-63e059b74a30"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"token_type_ids\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crcz1wdG-d_s",
        "outputId": "38b3fd3f-78a2-4df1-f56d-b101762a6550"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 512, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(batch[\"input_ids\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "oX8GgzYX-d8e",
        "outputId": "5b51878b-3d93-4807-a28c-f0be9732cfa5"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] what were the font - versions that were available from core fonts for the web project published in 2000? [SEP] file name font name variants last version copyright sample arial32 arial for regular, bold version 2. monotype [EMPTY] arial. arial for regular, bold version 2. monotype [EMPTY] arialb32 arial black black version 2. monotype [EMPTY] ariblk arial black black version 2. monotype [EMPTY] arialblack arial black black version 2. monotype [EMPTY] andale32 andale mono regular version 2. monotype [EMPTY] andalemono andale mono regular version 2. monotype [EMPTY] mtcom. monotype. regular version 1. monotype [EMPTY] courie32 courier new for regular, bold version 2. monotype [EMPTY] couriernew courier new for regular, bold version 2. monotype [EMPTY] comic32. comic sans ms regular, bold version 2. microsoft [EMPTY] comic. exe comic sans ms regular, bold version 1. microsoft [EMPTY] comicsans. comic sans ms regular, bold version 2. microsoft [EMPTY] georgi32 georgia for windows regular, bold version 2. microsoft [EMPTY] georgia. exe georgia for windows regular, bold version 1. microsoft [EMPTY] georgia. sit georgia for apple regular, bold version 2. microsoft [EMPTY] impact32. impact for windows regular version 2. monotype [EMPTY] impact. exe impact for windows regular version 2. monotype [EMPTY] impact. sit impact for apple regular version 2. monotype [EMPTY] times32. times new roman regular, bold version 2. monotype [EMPTY] timesnew times new roman regular, bold version 2. monotype [EMPTY] trebuc32 trebuchet regular, bold version 1. microsoft [EMPTY] trebuc trebuchet regular, bold version 1. microsoft [EMPTY] trebuchet trebuchet regular, bold version 1. microsoft [EMPTY] verdan32 verdana regular, bold version 2. microsoft [EMPTY] verdana verdana regular, bold version 1. microsoft [EMPTY] verdana verdana regular, bold version 2. microsoft [EMPTY] webdin32 webdings symbol version 1. microsoft [EMPTY] webdings webdings symbol version 1. microsoft [EMPTY] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first example should not have any prev_labels set\n",
        "assert batch[\"token_type_ids\"][0][:,3].sum() == 0"
      ],
      "metadata": {
        "id": "xX1mJIVAPZUW"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(batch[\"input_ids\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_nbRjj_jPZQP",
        "outputId": "32fe2dfc-4d02-4da1-f919-08d9462f71ba"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] in what films has shruti haasan made a cameo appearance? [SEP] title year role ( s ) director language ( s ) notes ref. hey ram 2000 unknown kamal haasan tamil cameo appearance [EMPTY] hey ram 2000 unknown kamal haasan hindi cameo appearance [EMPTY] luck 2009 ayesha, natasha soham shah hindi [EMPTY] [EMPTY] anaganaga o dheerudu 2011 priya prakash kovelamudi telugu filmfare award for best female debut [EMPTY] dil toh baccha 2011 nikki narang madhur bhandarkar hindi [EMPTY] [EMPTY] 7aum arivu 2011 subha srinivasan ar murugadoss tamil filmfare award for best female debut [EMPTY] oh my friend 2011 siri venu sree raam telugu [EMPTY] [EMPTY] 3 2012 janani aishwarya r. tamil nominated — filmfare award for best [EMPTY] gabbar singh 2012 bhagyalakshmi harish shankar telugu [EMPTY] [EMPTY] balupu 2013 shruti gopichand malineni telugu [EMPTY] [EMPTY] ramaiya vastavaiya 2013 sona prabhu deva hindi [EMPTY] [EMPTY] d - day 2013 suraiya nikhil advani hindi [EMPTY] [EMPTY] ramayya vasthavayya 2013 ammulu harish shankar telugu [EMPTY] [EMPTY] yevadu 2014 manju vamsi paidipally telugu [EMPTY] [EMPTY] race gurram 2014 spandana surender reddy telugu filmfare award for best actress – [EMPTY] aagadu 2014 zintamali srinu vaitla telugu special appearance in the song \" [EMPTY] poojai 2014 divya hari tamil [EMPTY] [EMPTY] tevar 2015 unknown amit sharma hindi special appearance in the song \" [EMPTY] gabbar is back 2015 shruti krish hindi [EMPTY] [EMPTY] srimanthudu 2015 charuseela koratala siva telugu nominated — filmfare award for best [EMPTY] welcome back 2015 ranjana anees bazmee hindi [EMPTY] [EMPTY] puli 2015 pavazhamalli chimbu deven tamil [EMPTY] [EMPTY] vedalam 2015 swetha siva tamil [EMPTY] [EMPTY] rocky handsome 2016 rukshida nishikant kamat hindi [EMPTY] [EMPTY] premam 2016 sithara chandoo mondeti telugu [EMPTY] [EMPTY] si3 2017 vidhya hari tamil [EMPTY] [EMPTY] katamarayudu 2017 avanthika kishore kumar pardasany telugu [EMPTY] [EMPTY] behen hogi teri 2017 binny ajay k. pannalal hindi [EMPTY] [EMPTY] power tba tba mahesh manjrekar hindi filming [EMPTY] laabam tba tba s. p. jananathan tamil filming [EMPTY] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assert batch[\"labels\"][0].sum() == batch[\"token_type_ids\"][1][:,3].sum()\n",
        "# print(batch[\"token_type_ids\"][1][:,3].sum())"
      ],
      "metadata": {
        "id": "0goNRWxBPZNM"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TapasForQuestionAnswering\n",
        "\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta5_IjQvPZKV",
        "outputId": "16c906b2-3a9b-4f3d-9130-d1196b58e826"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['column_output_bias', 'output_bias', 'output_weights', 'column_output_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TapasForQuestionAnswering(\n",
              "  (tapas): TapasModel(\n",
              "    (embeddings): TapasEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(1024, 768)\n",
              "      (token_type_embeddings_0): Embedding(3, 768)\n",
              "      (token_type_embeddings_1): Embedding(256, 768)\n",
              "      (token_type_embeddings_2): Embedding(256, 768)\n",
              "      (token_type_embeddings_3): Embedding(2, 768)\n",
              "      (token_type_embeddings_4): Embedding(256, 768)\n",
              "      (token_type_embeddings_5): Embedding(256, 768)\n",
              "      (token_type_embeddings_6): Embedding(10, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.07, inplace=False)\n",
              "    )\n",
              "    (encoder): TapasEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): TapasPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.07, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zK1Vv8tTBwoR"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "   print(\"Epoch:\", epoch)\n",
        "   for idx, batch in enumerate(train_dataloader):\n",
        "        # get the inputs;\n",
        "        print(\"idx, Batch:\",idx,batch)\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
        "                       labels=labels)\n",
        "        loss = outputs.loss\n",
        "        print(\"Loss:\", loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fvi_2lVBPZHH",
        "outputId": "d4ff76f5-5a5b-4455-9ff9-05e7a841263d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "feta_id                                                             12019\n",
            "table_source_json               totto_source/train_json/example-4318.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Core_fonts_for_th...\n",
            "table_page_title                                   Core fonts for the Web\n",
            "table_section_title                               List of fonts and files\n",
            "table_array             [[File name, Font name, Variants, Last version...\n",
            "highlighted_cell_ids    [[(1, 1), (1, 3), (9, 1), (9, 3), (20, 1), (20...\n",
            "question                [What were the font-versions that were availab...\n",
            "answer                  [The font-versions that were available from Co...\n",
            "source                                                     mturk-approved\n",
            "Name: 0, dtype: object\n",
            "feta_id                                                             10691\n",
            "table_source_json               totto_source/train_json/example-2990.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Shruti_Haasan_fil...\n",
            "table_page_title                                Shruti Haasan filmography\n",
            "table_section_title                                           Filmography\n",
            "table_array             [[Title, Year, Role(s), Director, Language(s),...\n",
            "highlighted_cell_ids    [[(1, 0), (1, 1), (1, 4), (1, 5), (2, 0), (2, ...\n",
            "question                [In what films has Shruti Haasan made a cameo ...\n",
            "answer                  [Shruti Haasan made a cameo appearance in Tami...\n",
            "source                                                           internal\n",
            "Name: 1, dtype: object\n",
            "feta_id                                                              8300\n",
            "table_source_json                totto_source/train_json/example-599.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/List_of_Assyrian_...\n",
            "table_page_title                                   List of Assyrian kings\n",
            "table_section_title                 Dynasty of Puzur-Ashur (2025–1749 BC)\n",
            "table_array             [[#, Image, King, Reign, Succession, Notes, Re...\n",
            "highlighted_cell_ids           [[(5, 2), (6, 2), (6, 4), (7, 2), (7, 4)]]\n",
            "question                [On the Assyrian King List, for whom is Sargon...\n",
            "answer                  [On the Assyrian King List, Sargon appears as ...\n",
            "source                                                           internal\n",
            "Name: 2, dtype: object\n",
            "idx, Batch: 0 {'input_ids': tensor([[ 101, 2054, 2020,  ...,    0,    0,    0],\n",
            "        [ 101, 1999, 2054,  ...,    0,    0,    0],\n",
            "        [ 101, 2006, 1996,  ..., 6182,    1,    0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'numeric_values': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]]), 'numeric_values_scale': tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
            "        [ 1.,  1.,  1.,  ..., 20.,  1.,  1.]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [1, 6, 9,  ..., 0, 0, 0],\n",
            "         [1, 7, 9,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 0]])}\n",
            "Loss: 1.57243812084198\n",
            "feta_id                                                              8107\n",
            "table_source_json                totto_source/train_json/example-406.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/List_of_Stanley_C...\n",
            "table_page_title                            List of Stanley Cup champions\n",
            "table_section_title                                          Active teams\n",
            "table_array             [[Apps, Team, Wins, Losses, Win %, Years of ap...\n",
            "highlighted_cell_ids                   [[(1, 1), (1, 2), (3, 1), (3, 2)]]\n",
            "question                [How many Stanley Cup championships did Toront...\n",
            "answer                  [The Toronto Maple Leafs has won thirteen Stan...\n",
            "source                                                           internal\n",
            "Name: 3, dtype: object\n",
            "feta_id                                                             10564\n",
            "table_source_json               totto_source/train_json/example-2863.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Estadio_El%C3%ADa...\n",
            "table_page_title                                    Estadio Elías Aguirre\n",
            "table_section_title                          International matches hosted\n",
            "table_array             [[Date, Team #1, Res., Team #2, Round, Attenda...\n",
            "highlighted_cell_ids    [[(1, 1), (1, 2), (1, 3), (1, 4), (5, 1), (5, ...\n",
            "question                [What were the first and final Copa América ma...\n",
            "answer                  [The game that opened the Elías Aguirre's part...\n",
            "source                                                           internal\n",
            "Name: 4, dtype: object\n",
            "feta_id                                                              1493\n",
            "table_source_json                 totto_source/dev_json/example-1492.json\n",
            "page_wikipedia_url      http://en.wikipedia.org/wiki/Ivor_Evans_(footb...\n",
            "table_page_title                       Ivor Evans (footballer, born 1966)\n",
            "table_section_title                                     Career statistics\n",
            "table_array             [[Club, Year, League, Apps, Goals], [Vancouver...\n",
            "highlighted_cell_ids    [[(1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, ...\n",
            "question                [Which leagues did Ivor Evans play in during h...\n",
            "answer                  [During his career, Ivor Evans played in the C...\n",
            "source                                                           internal\n",
            "Name: 5, dtype: object\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-7953b9d6dcee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# get the inputs;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idx, Batch:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-e864aabad6d8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                   \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                   \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# remove the batch dimension which the tokenizer adds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m             )\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         )\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         )\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_batch_prepare_for_model\u001b[0;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mprev_answer_coordinates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                 \u001b[0mprev_answer_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m             )\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer_coordinates\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0manswer_text\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_answer_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mnumeric_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0mnumeric_values_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_values_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mget_answer_ids\u001b[0;34m(self, column_ids, row_ids, tokenized_table, answer_texts_question, answer_coordinates_question)\u001b[0m\n\u001b[1;32m   1775\u001b[0m                 \u001b[0manswer_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manswer_texts_question\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             )\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_answer_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coordinates_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m     def _pad(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_get_answer_ids\u001b[0;34m(self, column_ids, row_ids, answer_coordinates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Couldn't find all answers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manswer_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Couldn't find all answers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['feta_id'] == 2226]"
      ],
      "metadata": {
        "id": "myjViawEPZD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item = data.iloc[5]\n",
        "table = pd.DataFrame(data[\"table_array\"][5]) # TapasTokenizer expects the table data to be text only\n",
        "  # this means it's the first table-question pair in a sequence\n",
        "table.columns = table.iloc[0]\n",
        "table = table.iloc[1: , :].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "qgSZZYvrPZA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item"
      ],
      "metadata": {
        "id": "bBO-gvzPPY9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item.highlighted_cell_ids"
      ],
      "metadata": {
        "id": "bOmIW4n3AZpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table.head()"
      ],
      "metadata": {
        "id": "tWxnl3WyPY6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "files = glob.glob(os.getcwd() + \"/path/to/training set/folder/**/*.xml\", recursive=True)\n",
        "triple_re=re.compile('(\\d)triples')\n",
        "data_dct={}\n",
        "for file in files:\n",
        "    tree = ET.parse(file)\n",
        "    root = tree.getroot()\n",
        "    triples_num=int(triple_re.findall(file)[0])\n",
        "    for sub_root in root:\n",
        "        for ss_root in sub_root:\n",
        "            strutured_master=[]\n",
        "            unstructured=[]\n",
        "            for entry in ss_root:\n",
        "                unstructured.append(entry.text)\n",
        "                strutured=[triple.text for triple in entry]\n",
        "                strutured_master.extend(strutured)\n",
        "            unstructured=[i for i in unstructured if i.replace('\\n','').strip()!='' ]\n",
        "            strutured_master=strutured_master[-triples_num:]\n",
        "            strutured_master_str=(' && ').join(strutured_master)\n",
        "            data_dct[strutured_master_str]=unstructured\n",
        "mdata_dct={\"prefix\":[], \"input_text\":[], \"target_text\":[]}\n",
        "for st,unst in data_dct.items():\n",
        "    for i in unst:\n",
        "        mdata_dct['prefix'].append('webNLG')\n",
        "        mdata_dct['input_text'].append(st)\n",
        "        mdata_dct['target_text'].append(i)\n",
        "\n",
        "\n",
        "df=pd.DataFrame(mdata_dct)\n",
        "df.to_csv('webNLG2020_train.csv')"
      ],
      "metadata": {
        "id": "oOzzl8LqFI3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tyZHrNj8FI0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xbbhvmaaFIyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2hsjyZDEFIub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sbNkxfIxFIrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}